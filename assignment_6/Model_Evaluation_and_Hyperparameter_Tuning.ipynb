{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries\n"
      ],
      "metadata": {
        "id": "ew8rS_kcHt-w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4FNz3IUsFHbo"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Preprocess Titanic Dataset"
      ],
      "metadata": {
        "id": "yUNZcr32H_8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "titanic = sns.load_dataset(\"titanic\")\n",
        "\n",
        "# Select useful features\n",
        "df = titanic[[\"survived\", \"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"embarked\"]]\n",
        "\n",
        "# Drop missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical columns\n",
        "le_sex = LabelEncoder()\n",
        "le_embarked = LabelEncoder()\n",
        "df[\"sex\"] = le_sex.fit_transform(df[\"sex\"])\n",
        "df[\"embarked\"] = le_embarked.fit_transform(df[\"embarked\"])\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop(\"survived\", axis=1)\n",
        "y = df[\"survived\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "2aNWY-iOFXav"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Multiple Models"
      ],
      "metadata": {
        "id": "XuZ8Zvz9HkoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Support Vector Machine\": SVC(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    results[name] = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1 Score\": f1_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "# Display\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"Model Evaluation Results:\\n\")\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACybjImGFhFY",
        "outputId": "029e2ec7-8ef9-43fd-e0f2-f4745d154122"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation Results:\n",
            "\n",
            "                        Accuracy  Precision    Recall  F1 Score\n",
            "Logistic Regression     0.797203   0.854167  0.650794  0.738739\n",
            "Support Vector Machine  0.825175   0.865385  0.714286  0.782609\n",
            "Random Forest           0.783217   0.766667  0.730159  0.747967\n",
            "Decision Tree           0.685315   0.666667  0.571429  0.615385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "PkRWy8kWIOsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GridSearchCV for SVC\n",
        "\n",
        "param_grid_svc = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "grid_svc = GridSearchCV(SVC(), param_grid_svc, cv=5, scoring='f1')\n",
        "grid_svc.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest SVC Parameters from GridSearchCV:\")\n",
        "print(grid_svc.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ppro3L_9Flo-",
        "outputId": "2c69339a-07e4-4983-80c1-a4c932157e63"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best SVC Parameters from GridSearchCV:\n",
            "{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RandomizedSearchCV for RandomForest\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_dist_rf = {\n",
        "    \"n_estimators\": randint(50, 200),\n",
        "    \"max_depth\": [None, 5, 10, 20],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4],\n",
        "}\n",
        "\n",
        "random_search_rf = RandomizedSearchCV(RandomForestClassifier(), param_dist_rf,\n",
        "                                      n_iter=10, cv=5, scoring='f1', random_state=42)\n",
        "random_search_rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest RandomForest Parameters from RandomizedSearchCV:\")\n",
        "print(random_search_rf.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4C5HZdFF7-t",
        "outputId": "12387e95-7941-45ad-8f8c-1a23da64c358"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best RandomForest Parameters from RandomizedSearchCV:\n",
            "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 180}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Tuned Models"
      ],
      "metadata": {
        "id": "DPH53wHsKU3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_models = {\n",
        "    \"Tuned SVC\": grid_svc.best_estimator_,\n",
        "    \"Tuned Random Forest\": random_search_rf.best_estimator_\n",
        "}\n",
        "\n",
        "tuned_results = {}\n",
        "\n",
        "for name, model in final_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    tuned_results[name] = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1 Score\": f1_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "tuned_df = pd.DataFrame(tuned_results).T\n",
        "print(\"\\nTuned Model Evaluation Results:\\n\")\n",
        "print(tuned_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODySRpnBGF0K",
        "outputId": "1f521e89-0ebc-4b71-a884-49eac60d9bd0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tuned Model Evaluation Results:\n",
            "\n",
            "                     Accuracy  Precision    Recall  F1 Score\n",
            "Tuned SVC            0.825175   0.865385  0.714286  0.782609\n",
            "Tuned Random Forest  0.790210   0.823529  0.666667  0.736842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best Model"
      ],
      "metadata": {
        "id": "NiAST3d7Kd5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary = pd.concat([results_df, tuned_df])\n",
        "print(\"\\nAll Model Performance Summary:\\n\")\n",
        "print(summary.sort_values(by=\"F1 Score\", ascending=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chPg183gGGkI",
        "outputId": "9fa3cdc0-d681-4d2e-b909-7b6cf149890e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "All Model Performance Summary:\n",
            "\n",
            "                        Accuracy  Precision    Recall  F1 Score\n",
            "Support Vector Machine  0.825175   0.865385  0.714286  0.782609\n",
            "Tuned SVC               0.825175   0.865385  0.714286  0.782609\n",
            "Random Forest           0.783217   0.766667  0.730159  0.747967\n",
            "Logistic Regression     0.797203   0.854167  0.650794  0.738739\n",
            "Tuned Random Forest     0.790210   0.823529  0.666667  0.736842\n",
            "Decision Tree           0.685315   0.666667  0.571429  0.615385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Model Selection Summary"
      ],
      "metadata": {
        "id": "6RKxIS0cKpGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSummary and Conclusion:\\n\")\n",
        "\n",
        "summary_text = \"\"\"\n",
        "After training and evaluating multiple machine learning models on the Titanic dataset, we observed the following:\n",
        "\n",
        "1) The best-performing model in terms of F1 Score was Support Vector Machine (SVC) with an F1 Score of 0.7826,\n",
        "which remained the same even after hyperparameter tuning (Tuned SVC), indicating the initial parameters were already optimal.\n",
        "\n",
        "2)Random Forest and Logistic Regression also performed reasonably well, with F1 Scores of 0.7479 and 0.7387, respectively.\n",
        "Tuned Random Forest gave a slight improvement in precision but did not outperform the original SVC model.\n",
        "\n",
        "3) Decision Tree showed the weakest performance across all metrics, suggesting it may not generalize well for this dataset.\n",
        "\n",
        "Conclusion:\n",
        "The Support Vector Machine (SVC) model is selected as the best-performing model based on F1 Score and overall balanced performance across all evaluation metrics. No further improvement was observed with tuning, confirming its robustness on this problem.\n",
        "\"\"\"\n",
        "\n",
        "print(summary_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tVckTvtHDWa",
        "outputId": "401299ae-25bb-4f6e-99b7-a3bb5466f29a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary and Conclusion:\n",
            "\n",
            "\n",
            "After training and evaluating multiple machine learning models on the Titanic dataset, we observed the following:\n",
            "\n",
            "1) The best-performing model in terms of F1 Score was Support Vector Machine (SVC) with an F1 Score of 0.7826, \n",
            "which remained the same even after hyperparameter tuning (Tuned SVC), indicating the initial parameters were already optimal.\n",
            "\n",
            "2)Random Forest and Logistic Regression also performed reasonably well, with F1 Scores of 0.7479 and 0.7387, respectively.\n",
            "Tuned Random Forest gave a slight improvement in precision but did not outperform the original SVC model.\n",
            "\n",
            "3) Decision Tree showed the weakest performance across all metrics, suggesting it may not generalize well for this dataset.\n",
            "\n",
            "Conclusion: \n",
            "The Support Vector Machine (SVC) model is selected as the best-performing model based on F1 Score and overall balanced performance across all evaluation metrics. No further improvement was observed with tuning, confirming its robustness on this problem.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}